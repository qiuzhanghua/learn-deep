{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')   \n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "device = default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义第一种残差模块BasicBlock\n",
    "class BasicBlock(nn.Module):\n",
    "    # 设置expansion为1，用于计算最终输出特征图的通道数\n",
    "    expansion = 1\n",
    "\n",
    "    # 构造函数，接收输入通道数inplanes，输出通道数planes，步长stride和下采样层downsample\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        # 定义第一个卷积层，用3x3的卷积核对输入特征图进行卷积，输出通道数为planes，步长为stride，填充为1\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        # BN层\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        # 激活函数ReLU\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # 定义第二个卷积层，用3x3的卷积核对输入特征图进行卷积，输出通道数为planes，步长默认为1，填充为1\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1, bias=False)\n",
    "        # BN层\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        # 下采样层，用于调整输入x的维度\n",
    "        self.downsample = downsample\n",
    "        # 保存步长\n",
    "        self.stride = stride\n",
    "\n",
    "    # 定义前向传播函数\n",
    "    def forward(self, x):\n",
    "        # 保存输入特征图\n",
    "        identity = x\n",
    "\n",
    "        # 卷积+BN+ReLU\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # 卷积+BN\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # 如果定义了下采样层，则调整输入x的维度\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # 将identity和out相加，并使用ReLU激活函数激活\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # 返回输出特征图\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义第二种残差模块Bottleneck\n",
    "class Bottleneck(nn.Module):\n",
    "    # 设置expansion为4，用于计算最终输出特征图的通道数\n",
    "    expansion = 4\n",
    "\n",
    "    # 构造函数，接收输入通道数inplanes，输出通道数planes，步长stride和下采样层downsample\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        # 定义第一个卷积层，用1x1的卷积核对输入特征图进行卷积，输出通道数为planes\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        # BN层\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        # 定义第二个卷积层，用3x3的卷积核对第一个卷积层的输出进行卷积，输出通道数为planes，步长为stride，填充为1\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        # BN层\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        # 定义第三个卷积层，用1x1的卷积核对第二个卷积层的输出进行卷积，输出通道数为planes * 4\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        # BN层\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        # 激活函数ReLU\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # 下采样层，用于调整输入x的维度\n",
    "        self.downsample = downsample\n",
    "        # 保存步长\n",
    "        self.stride = stride\n",
    "\n",
    "    # 定义前向传播函数\n",
    "    def forward(self, x):\n",
    "        # 保存输入特征图\n",
    "        identity = x\n",
    "\n",
    "        # 卷积+BN+ReLU\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # 卷积+BN+ReLU\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # 卷积+BN\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        # 如果定义了下采样层，则调整输入x的维度\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # 将identity和out相加，并使用ReLU激活函数激活\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # 返回输出特征图\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义ResNet的网络结构\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    # 构造函数，接收残差块类型block、残差块数量列表layers和类别数num_classes\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        super().__init__()\n",
    "        # 定义第一个卷积层，用7x7的卷积核对输入特征图进行卷积，输出通道数为64，步长为2，填充为3\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # BN层\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        # 激活函数ReLU\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # 定义3x3最大池化层对特征图进行池化，步长为2，填充为1\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # 初始化输入通道数inplanes为64\n",
    "        self.inplanes = 64\n",
    "        # 定义layer1，使用_make_layer函数生成一个layer，通道数64，包含layers[0]个block\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        # 定义layer2，使用_make_layer函数生成一个layer，通道数128，包含layers[1]个block，步长为2\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        # 定义layer3，使用_make_layer函数生成一个layer，通道数256，包含layers[2]个block，步长为2\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        # 定义layer4，使用_make_layer函数生成一个layer，通道数512，包含layers[3]个block，步长为2\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        # 平均池化层，输出大小为channel*1*1\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        # 定义全连接层，将输入维度设置为512 * block.expansion，输出维度设置为num_classes\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    # 生成网络结构的函数，根据传入的配置，拼接出对应的网络结构\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        # 下采样层一开始为None，用于调整输入的维度\n",
    "        downsample = None\n",
    "        # 如果步长不为1或者输入通道数与输出通道数不一致，则需要对输入特征进行调整\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            # 定义下采样层，包括1x1卷积和BN层\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        # 定义一个layers列表\n",
    "        layers = []\n",
    "        # 将第一个block添加到layers列表中\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        # 更新inplanes为下一个基本块的输入通道数\n",
    "        self.inplanes = planes * block.expansion\n",
    "        # 添加剩余的基本块到layers列表中\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        # 返回所有的block\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    # 定义前向传播函数\n",
    "    def forward(self, x):\n",
    "        # 第一部分，7x7卷积+BN+ReLU+最大池化层\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        # 第二部分，4组残差模块\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        # 第三部分，平均池化+全连接层\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        # 输出\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 封装函数对应5个模型，num_classes表示类别数\n",
    "# 其中数值与网络结构表格中的数值完全一致，可参考论文结构表\n",
    "def resnet18(num_classes=1000):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
    "\n",
    "def resnet34(num_classes=1000):\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes)\n",
    "\n",
    "def resnet50(num_classes=1000):\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes=num_classes)\n",
    "\n",
    "def resnet101(num_classes=1000):\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3], num_classes=num_classes)\n",
    "\n",
    "def resnet152(num_classes=1000):\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看模型结构及参数量，input_size表示示例输入数据的维度信息\n",
    "# summary(resnet34(), input_size=(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import *\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# 定义模型、优化器、损失函数\n",
    "model = resnet18(num_classes=102).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 设置训练集的数据变换，进行数据增强\n",
    "trainform_train = transforms.Compose([\n",
    "    transforms.RandomRotation(30), # 随机旋转 -30度到30度之间\n",
    "    transforms.RandomResizedCrop((224, 224)), # 随机比例裁剪并进行resize\n",
    "    transforms.RandomHorizontalFlip(p = 0.5), # 随机水平翻转\n",
    "    transforms.RandomVerticalFlip(p = 0.5), # 随机垂直翻转\n",
    "    transforms.ToTensor(),  # 将数据转换为张量\n",
    "    # 对三通道数据进行归一化(均值，标准差)，数值是从ImageNet数据集上的百万张图片中随机抽样计算得到\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 设置测试集的数据变换，不进行数据增强，仅使用resize和归一化\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # resize\n",
    "    transforms.ToTensor(),  # 将数据转换为张量\n",
    "    # 对三通道数据进行归一化(均值，标准差)，数值是从ImageNet数据集上的百万张图片中随机抽样计算得到\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 加载训练数据，需要特别注意的是Flowers102数据集，test簇的数据量较多些，所以这里使用\"test\"作为训练集\n",
    "train_dataset = datasets.Flowers102(root='data', split=\"test\", download=True, transform=trainform_train)\n",
    "# 实例化训练数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "# 加载测试数据，使用\"train\"作为测试集\n",
    "test_dataset = datasets.Flowers102(root='data', split=\"train\", download=True, transform=transform_test)\n",
    "# 实例化测试数据加载器\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "# 设置epoch数并开始训练\n",
    "num_epochs = 200  # 设置epoch数\n",
    "loss_history = []  # 创建损失历史记录列表\n",
    "acc_history = []   # 创建准确率历史记录列表\n",
    "\n",
    "# tqdm用于显示进度条并评估任务时间开销\n",
    "for epoch in tqdm(range(num_epochs), file=sys.stdout):\n",
    "    # 记录损失和预测正确数\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    # 批量训练\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        # 将数据转移到指定计算资源设备上\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 预测、损失函数、反向传播\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 记录训练集loss\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # 测试模型，不计算梯度\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # 将数据转移到指定计算资源设备上\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 预测\n",
    "            outputs = model(inputs)\n",
    "            # 记录测试集预测正确数\n",
    "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        \n",
    "    # 记录训练集损失和测试集准确率\n",
    "    loss_history.append(np.log10(total_loss))  # 将损失加入损失历史记录列表，由于数值有时较大，这里取对数\n",
    "    acc_history.append(total_correct / len(test_dataset))# 将准确率加入准确率历史记录列表\n",
    "    \n",
    "    # 打印中间值\n",
    "    if epoch % 10 == 0:\n",
    "        tqdm.write(\"Epoch: {0} Loss: {1} Acc: {2}\".format(epoch, loss_history[-1], acc_history[-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses_history, label='Loss')\n",
    "plt.plot(accuracies_history, label='Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Accuracy:', accuracies_history[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
