{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "default_device_name = (\n",
    "         'cuda' if torch.cuda.is_available() \n",
    "    else 'mps' if torch.backends.mps.is_available() \n",
    "    else 'cpu'\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() \n",
    "                else 'mps' if torch.backends.mps.is_available() \n",
    "                else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据预处理方法，将数据转换为 Tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "mnist_dataset = datasets.MNIST(root='data', train=True, transform=transform, download=True)\n",
    "# 加载数据，并使用 DataLoader 进行分批处理，batch_size 设置为 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_dataset, batch_size=64, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# 定义要显示的样本数量\n",
    "num_samples = 12\n",
    "\n",
    "# 创建一个matplotlib绘图窗口，并显示指定数量的MNIST样本\n",
    "fig, axs = plt.subplots(1, num_samples, figsize=(10,10))\n",
    "for i in range(num_samples):\n",
    "    # 从MNIST数据集中随机选择一个样本\n",
    "    idx = torch.randint(len(mnist_dataset), size=(1,)).item()\n",
    "    # 获取该样本的图像信息\n",
    "    img, _ = mnist_dataset[idx]\n",
    "    # 在绘图窗口中显示该样本的图像\n",
    "    axs[i].imshow(img.squeeze(), cmap='gray')\n",
    "    # 不显示坐标轴\n",
    "    axs[i].axis('off')\n",
    "# 显示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数\n",
    "input_dim = 28  # MNIST数据集图像长宽\n",
    "latent_dim = 2  # 隐变量维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义VAE的网络结构\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # 编码器部分，都使用全连接\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)   # 输入x_dim，输出h_dim1\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)  # 输入h_dim1，输出h_dim2\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)  # 输入h_dim2，输出z_dim，输出mu，均值\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)  # 输入h_dim2，输出z_dim，输出log_var，方差的对数\n",
    "\n",
    "        # 解码器部分，都使用全连接\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim2)   # 输入z_dim，输出h_dim2\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)  # 输入h_dim2，输出h_dim1\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)   # 输入h_dim1，输出x_dim\n",
    "    \n",
    "    # 编码器处理部分\n",
    "    def encoder(self, x):\n",
    "        # 全连接+ReLU\n",
    "        h = torch.relu(self.fc1(x))\n",
    "        h = torch.relu(self.fc2(h))\n",
    "        # 返回mu和log_var\n",
    "        return self.fc31(h), self.fc32(h) \n",
    "    \n",
    "    # 解码器处理部分\n",
    "    def decoder(self, z):\n",
    "        # 全连接+ReLU\n",
    "        h = torch.relu(self.fc4(z))\n",
    "        h = torch.relu(self.fc5(h))\n",
    "        # 接sigmoid激活函数，输出重建后的x\n",
    "        return torch.sigmoid(self.fc6(h)) \n",
    "    \n",
    "    # 重参数化技巧\n",
    "    def sampling(self, mu, log_var):\n",
    "        # 计算标准差\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        # 从标准正态分布中随机采样eps\n",
    "        eps = torch.randn_like(std)\n",
    "        # 返回z\n",
    "        return mu + eps * std\n",
    "    \n",
    "    # 定义前向传播函数\n",
    "    def forward(self, x):\n",
    "        # 编码器，输出mu和log_var\n",
    "        mu, log_var = self.encoder(x.view(-1, input_dim*input_dim))\n",
    "        # 重参数化\n",
    "        z = self.sampling(mu, log_var)\n",
    "        # 返回解码器输出、mu、log_var和z\n",
    "        return self.decoder(z), mu, log_var, z\n",
    "#%%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化VAE模型\n",
    "vae = VAE(x_dim=input_dim*input_dim, h_dim1= 512, h_dim2=256, z_dim=latent_dim).to(device)\n",
    "\n",
    "# 定义Adam优化器，用于优化VAE模型的参数，学习率0.001\n",
    "optimizer = optim.Adam(vae.parameters(), lr = 0.001)\n",
    "\n",
    "# 定义VAE的损失函数，其中包含重构误差和KL散度\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    # 重构误差，使用二元交叉熵损失函数\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, input_dim*input_dim), reduction='sum')\n",
    "    \n",
    "    # KL散度，计算高斯分布之间的散度\n",
    "    # 详见VAE论文中的Appendix B\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    \n",
    "    # 将重构误差和KL散度相加作为总损失\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义训练轮数\n",
    "n_epochs = 20\n",
    "\n",
    "# 循环开始训练\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # 进入训练模式\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    # 遍历训练数据集\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 前向传播，计算重构误差和KL散度\n",
    "        recon_batch, mu, log_var, z = vae(data)\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "        \n",
    "        # 反向传播，记录损失值，更新模型参数\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 输出平均损失\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))\n",
    "    \n",
    "    # 进入评估模式\n",
    "    vae.eval()\n",
    "    # 生成新样本\n",
    "    with torch.no_grad():\n",
    "        # 随机生成正态分布，并使用解码器将采样结果转换为新的样本\n",
    "        z = torch.randn(num_samples, latent_dim).to(device)\n",
    "        sample = vae.decoder(z).cpu()\n",
    "        images = sample.view(num_samples, input_dim, input_dim).numpy()\n",
    "\n",
    "        # 可视化生成的样本\n",
    "        fig, axs = plt.subplots(1, num_samples, figsize=(10,10))\n",
    "        for i in range(num_samples):\n",
    "            axs[i].imshow(images[i], cmap='gray')\n",
    "            axs[i].axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "noise_dim = 100  # 随机噪声维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据预处理方法，将数据转换为 Tensor，并进行归一化\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将图像转换为张量\n",
    "    transforms.Normalize([0.5], [0.5])   # 进行归一化，均值为0.5，标准差为0.5\n",
    "])\n",
    "\n",
    "# 加载 MNIST 数据集\n",
    "mnist_dataset = datasets.MNIST(root='data', train=True, transform=transform, download=True)\n",
    "# 加载数据，并使用 DataLoader 进行分批处理，batch_size 设置为 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成器模型\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # 定义每个block的结构，全连接+BN+ReLU\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)] # 全连接\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat)) # BN层\n",
    "            layers.append(nn.ReLU(inplace=True)) # ReLU激活函数\n",
    "            return layers\n",
    "\n",
    "        # 定义生成器的网络结构，4个block\n",
    "        self.model = nn.Sequential(\n",
    "            *block(noise_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, input_dim * input_dim), # 全连接层输出\n",
    "            nn.Tanh() # Tanh激活函数，将输出映射到[-1,1]之间\n",
    "        )\n",
    "\n",
    "    # 定义前向传播函数\n",
    "    def forward(self, z):\n",
    "        # 经过生成器模型\n",
    "        img = self.model(z)\n",
    "        # 调整输出维度\n",
    "        img = img.view(-1, 1, input_dim, input_dim)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义判别器模型\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # 定义判别器的网络模型，3个全连接层\n",
    "        self.model = nn.Sequential(\n",
    "            # 全连接层，输入维度为28*28，输出维度为512\n",
    "            nn.Linear(input_dim * input_dim, 512),\n",
    "            # ReLU激活函数\n",
    "            nn.ReLU(inplace=True),\n",
    "            # 全连接层，输入维度为512，输出维度为256\n",
    "            nn.Linear(512, 256),\n",
    "            # ReLU激活函数\n",
    "            nn.ReLU(inplace=True),\n",
    "            # 全连接层，输入维度为256，输出维度为1\n",
    "            nn.Linear(256, 1),\n",
    "            # sigmoid激活函数，将输出映射到(0,1)之间\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten将x的维度降为一维\n",
    "        x = torch.flatten(x, 1)\n",
    "        # 输入x并计算输出\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义二元交叉熵损失函数\n",
    "adversarial_loss = torch.nn.BCELoss().to(device)\n",
    "\n",
    "# 实例化生成器和判别器\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# 定义生成器和判别器的优化器，都使用Adam算法，学习率设为0.001，betas设为(0.5, 0.999)\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr = 0.001, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr = 0.001, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练轮数\n",
    "n_epochs = 40\n",
    "from torch import Tensor\n",
    "# 循环开始训练\n",
    "for epoch in range(n_epochs):\n",
    "    # 分别记录每轮生成器和判别器的loss\n",
    "    generator_loss, discriminator_loss = 0, 0\n",
    "    # 遍历训练数据集\n",
    "    for batch_idx, (imgs, _) in enumerate(train_loader):\n",
    "\n",
    "        # 定义真实标签的Tensor，数值全为1.0，不需要计算梯度\n",
    "        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        # 定义假标签的Tensor，数值全为0.0，不需要计算梯度\n",
    "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # 将真实图片转化为Tensor\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # 开始训练生成器\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # 随机生成一个满足正态分布均值为0，方差为1的z\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], noise_dim)))).to(device)\n",
    "\n",
    "        # 通过生成器生成图片\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # 计算生成器的损失并记录\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "        generator_loss += g_loss.item()\n",
    "\n",
    "        # 反向传播并更新参数\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # 开始训练判别器\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # 计算判别器在真实图片上的损失\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "        # 计算判别器在生成图片上的损失\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        \n",
    "        # 计算判别器的总损失并记录\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        discriminator_loss += d_loss.item()\n",
    "\n",
    "        # 反向传播并更新参数\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "    # 输出每一轮的生成器和判别器的平均损失\n",
    "    print(\"====> Epoch: {} Generator loss: {:.4f} Discriminator loss: {:.4f}\".format(\n",
    "        epoch, generator_loss / len(train_loader.dataset), discriminator_loss / len(train_loader.dataset)))\n",
    "    \n",
    "    # 将最后生成的图片转换为numpy数组\n",
    "    images = gen_imgs.view(-1, 28, 28).detach().cpu().numpy()\n",
    "    # 可视化生成的样本\n",
    "    fig, axs = plt.subplots(1, num_samples, figsize=(10,10))\n",
    "    for i in range(num_samples):\n",
    "        axs[i].imshow(images[i], cmap='gray')\n",
    "        axs[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
