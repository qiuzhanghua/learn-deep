{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')   \n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    return torch.device('cpu')\n",
    "\n",
    "device = default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as pdr\n",
    "gs10 = pdr.get_data_fred('GS10')\n",
    "gs10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(gs10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(gs10)\n",
    "x = torch.tensor(gs10['GS10'].to_list())\n",
    "seq_len = 6\n",
    "batch_size = 4\n",
    "\n",
    "X_feature = torch.zeros((num - seq_len, seq_len))\n",
    "Y_feature = torch.zeros(num - seq_len, 1)\n",
    "\n",
    "for i in range(num - seq_len):\n",
    "    X_feature[i] = x[i:i+seq_len]\n",
    "    Y_feature[i] = x[i+seq_len]\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_feature[:num-seq_len], Y_feature[:num-seq_len]), \n",
    "                          batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_loader.dataset[:batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imput_size = seq_len\n",
    "output_size = 1\n",
    "hidden_size = 10\n",
    "lr = 0.01\n",
    "\n",
    "model = Model(imput_size, hidden_size, output_size).to(device)\n",
    "criterion = nn.MSELoss(reduction='none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "loss_history = []\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.sum().backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            total_loss += loss.sum().item() / loss.numel()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        loss_history.append(avg_loss)\n",
    "        print(f'epoch: {epoch+1}, Validation Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history, label='loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(X_feature.to(device)).cpu().detach().numpy()\n",
    "times = torch.arange(1, num + 1, dtype=torch.float32)\n",
    "\n",
    "plt.plot(times[:num - seq_len], gs10['GS10'][:num-seq_len], label='GS10')\n",
    "plt.plot(times[seq_len:], preds, label='prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "num = len(gs10)\n",
    "x = torch.tensor(gs10['GS10'].to_list())\n",
    "seq_len = 6\n",
    "batch_size = 4\n",
    "\n",
    "X_feature = torch.zeros((num - seq_len, seq_len))\n",
    "Y_label = torch.zeros(num - seq_len, seq_len)\n",
    "\n",
    "for i in range(seq_len):\n",
    "    X_feature[:, i] = x[i:num-seq_len+i]\n",
    "    Y_label[:, i] = x[i+1:num-seq_len+i+1]\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_feature[:num-seq_len].unsqueeze(2), Y_label[:num-seq_len]),\n",
    "                          batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_loader.dataset[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from tqdm import *\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_hiddens, n_layers):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.n_layers = n_layers\n",
    "        self.rnn = nn.RNN(input_size, num_hiddens, n_layers, batch_first = True)\n",
    "        self.linear = nn.Linear(num_hiddens, output_size)\n",
    "       \n",
    "    def forward(self, X):\n",
    "        batch_size = X.size(0)\n",
    "        state = self.begin_state(batch_size)\n",
    "        output, state = self.rnn(X, state)\n",
    "        output = self.linear(torch.relu(output))\n",
    "        return output, state\n",
    "\n",
    "    def begin_state(self, batch_size=1):\n",
    "        return  torch.zeros(self.n_layers, batch_size, self.num_hiddens)\n",
    "\n",
    "# 定义超参数\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "num_hiddens = 10\n",
    "n_layers = 1\n",
    "lr = 0.01\n",
    "\n",
    "# 建立模型\n",
    "model = RNNModel(input_size, output_size, num_hiddens, n_layers)\n",
    "criterion = nn.MSELoss(reduction='none')\n",
    "trainer = torch.optim.Adam(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "rnn_loss_history = []\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # 批量训练\n",
    "    for X, Y in train_loader:\n",
    "        trainer.zero_grad()\n",
    "        y_pred, state = model(X)\n",
    "        loss = criterion(y_pred.squeeze(), Y.squeeze())\n",
    "        loss.sum().backward()\n",
    "        trainer.step()\n",
    "    # 输出损失\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for X, Y in train_loader:\n",
    "            y_pred, state = model(X)\n",
    "            loss = criterion(y_pred.squeeze(), Y.squeeze())\n",
    "            total_loss += loss.sum()/loss.numel()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}: Validation loss = {avg_loss:.4f}')\n",
    "        rnn_loss_history.append(avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_history, label='loss')\n",
    "plt.plot(rnn_loss_history, label='RNN_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_preds,_ = model(X_feature.unsqueeze(2))\n",
    "preds.squeeze()\n",
    "time = torch.arange(1, num+1, dtype= torch.float32)  # 时间轴\n",
    "\n",
    "plt.plot(time[:num-seq_len], gs10['GS10'].to_list()[seq_len:num], label='gs10')\n",
    "plt.plot(time[:num-seq_len], preds, label='preds')\n",
    "plt.plot(time[:num-seq_len], rnn_preds[:,seq_len-1].detach().numpy(), label='RNN_preds')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
